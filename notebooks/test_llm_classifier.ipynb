{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLMClassifier Test\n",
        "\n",
        "Test the LLMClassifier on quark/gluon jet data using Google Gemini API.\n",
        "\n",
        "This notebook demonstrates:\n",
        "- Zero-shot jet classification with Gemini 2.5 Flash-Lite\n",
        "- Thinking budget control (512-24,576 tokens for Flash-Lite)\n",
        "- Token usage and cost tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
        "\n",
        "from vibe_jet_tagging import LLMClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "Load the quark/gluon jet dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10000 jets\n",
            "X shape: (10000, 139, 4)\n",
            "y shape: (10000,)\n",
            "Quark jets: 5074\n",
            "Gluon jets: 4926\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data_path = Path.cwd().parent / 'data' / 'qg_jets.npz'\n",
        "data = np.load(data_path)\n",
        "\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "\n",
        "print(f\"Loaded {len(X)} jets\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "print(f\"Quark jets: {(y == 1).sum()}\")\n",
        "print(f\"Gluon jets: {(y == 0).sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize LLMClassifier\n",
        "\n",
        "Set up the classifier with Google Gemini API.\n",
        "\n",
        "**Note:** You need a Gemini API key. Get one from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
        "\n",
        "Set it as an environment variable:\n",
        "```bash\n",
        "export GEMINI_API_KEY=\"your-key-here\"\n",
        "```\n",
        "\n",
        "Or add it to your `.env` file in the project root:\n",
        "```\n",
        "GEMINI_API_KEY='your-key-here'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Gemini API key found\n"
          ]
        }
      ],
      "source": [
        "# Load API key from .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Check if API key is set\n",
        "if 'GEMINI_API_KEY' not in os.environ:\n",
        "    print(\"WARNING: GEMINI_API_KEY not set. Please set it in .env file.\")\n",
        "    print(\"Create a .env file with: GEMINI_API_KEY='your-key-here'\")\n",
        "else:\n",
        "    print(\"âœ“ Gemini API key found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier initialized\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Template: simple_list\n",
            "Format: list\n",
            "Thinking budget: 1000\n"
          ]
        }
      ],
      "source": [
        "# Initialize classifier with Gemini API\n",
        "clf = LLMClassifier(\n",
        "    model_name=\"gemini-2.5-flash-lite-preview-09-2025\",  # No \"google/\" prefix\n",
        "    template_name=\"simple_list\",\n",
        "    format_type=\"list\",\n",
        "    templates_dir=str(Path.cwd().parent / 'templates'),\n",
        "    thinking_budget=1000,         # Control thinking tokens (512-24,576 for Flash-Lite)\n",
        "    max_tokens=2000               # Max output tokens (need enough for thinking + output)\n",
        ")\n",
        "\n",
        "# Fit (no-op for zero-shot)\n",
        "clf.fit([], [])\n",
        "\n",
        "print(\"Classifier initialized\")\n",
        "print(f\"Model: {clf.model_name}\")\n",
        "print(f\"Template: {clf.template_name}\")\n",
        "print(f\"Format: {clf.format_type}\")\n",
        "print(f\"Thinking budget: {clf.thinking_budget}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Single Jet Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True label: 1.0 (quark)\n",
            "\n",
            "Jet shape: (139, 4)\n",
            "Number of particles (pt > 0): 18\n",
            "\n",
            "ğŸ”§ API PARAMETERS\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Max output tokens: 2000\n",
            "Thinking budget: 1000\n",
            "\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“Š TOKEN USAGE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Prompt tokens:     757\n",
            "Completion tokens: 1\n",
            "Thinking tokens:   998\n",
            "â”œâ”€ Thinking:       998\n",
            "â””â”€ Output:         1\n",
            "Total tokens:      1,756\n",
            "\n",
            "ğŸ’° COST\n",
            "Input cost:        $0.000057\n",
            "Output cost:       $0.000300\n",
            "Call cost:         $0.000356\n",
            "\n",
            "âœ¨ RESPONSE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Content: 0\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ğŸ“ˆ CUMULATIVE STATISTICS\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Total prompt tokens:     757\n",
            "Total completion tokens: 1\n",
            "Total thinking tokens:   998\n",
            "Total tokens:            1,756\n",
            "\n",
            "ğŸ’° Total estimated cost: $0.000356\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "\n",
            "Predicted label: 0 (gluon)\n",
            "Correct: False\n"
          ]
        }
      ],
      "source": [
        "# Test on a single jet\n",
        "test_jet = X[0]\n",
        "true_label = y[0]\n",
        "\n",
        "print(f\"True label: {true_label} ({'quark' if true_label == 1 else 'gluon'})\")\n",
        "print(f\"\\nJet shape: {test_jet.shape}\")\n",
        "print(f\"Number of particles (pt > 0): {(test_jet[:, 0] > 0).sum()}\")\n",
        "\n",
        "# Make prediction\n",
        "prediction = clf.predict([test_jet], verbose=True)[0]\n",
        "print(f\"\\nPredicted label: {prediction} ({'quark' if prediction == 1 else 'gluon'})\")\n",
        "print(f\"Correct: {prediction == true_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PROMPT PREVIEW\n",
            "================================================================================\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Template: simple_list\n",
            "Format: list\n",
            "Max output tokens: 2000\n",
            "Thinking budget: 1000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT:\n",
            "--------------------------------------------------------------------------------\n",
            "You are a particle physics expert. Your task is to classify whether a jet is initiated by a quark (label: 1) or a gluon (label: 0).\n",
            "\n",
            "A jet consists of particles, each with the following properties:\n",
            "- pt: transverse momentum (GeV)\n",
            "- y: rapidity\n",
            "- phi: azimuthal angle (radians)\n",
            "- pid: particle ID\n",
            "\n",
            "Here is the jet data:\n",
            "Particle 1: pt=0.269 GeV, y=0.357, phi=4.741, pid=22\n",
            "Particle 2: pt=0.160 GeV, y=-0.256, phi=4.550, pid=22\n",
            "Particle 3: pt=1.149 GeV, y=-0.062, phi=4.504, pid=-211\n",
            "Particle 4: pt=4.132 GeV, y=0.174, phi=4.766, pid=-321\n",
            "Particle 5: pt=1.696 GeV, y=-0.212, phi=4.797, pid=-211\n",
            "Particle 6: pt=2.194 GeV, y=-0.052, phi=4.576, pid=22\n",
            "Particle 7: pt=1.619 GeV, y=-0.068, phi=4.646, pid=22\n",
            "Particle 8: pt=6.592 GeV, y=0.044, phi=4.766, pid=211\n",
            "Particle 9: pt=3.771 GeV, y=0.042, phi=4.755, pid=321\n",
            "Particle 10: pt=13.482 GeV, y=-0.028, phi=4.735, pid=-211\n",
            "Particle 11: pt=4.108 GeV, y=-0.024, phi=4.759, pid=22\n",
            "Particle 12: pt=21.646 GeV, y=-0.027, phi=4.760, pid=22\n",
            "Particle 13: pt=6.776 GeV, y=-0.030, phi=4.761, pid=22\n",
            "Particle 14: pt=13.255 GeV, y=-0.039, phi=4.749, pid=22\n",
            "Particle 15: pt=2.984 GeV, y=-0.037, phi=4.746, pid=22\n",
            "Particle 16: pt=37.374 GeV, y=-0.035, phi=4.755, pid=22\n",
            "Particle 17: pt=335.399 GeV, y=-0.033, phi=4.751, pid=22\n",
            "Particle 18: pt=44.214 GeV, y=-0.033, phi=4.754, pid=22\n",
            "\n",
            "Based on the particle content and kinematics, is this a quark jet (1) or gluon jet (0)?\n",
            "\n",
            "Respond with ONLY the number 0 or 1, nothing else.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "clf.preview_prompt(test_jet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Thinking Budget Control\n",
        "\n",
        "Test how different thinking budgets affect performance and token usage.\n",
        "\n",
        "For Gemini 2.5 Flash-Lite:\n",
        "- **Minimum**: 512 tokens (or 0 to disable)\n",
        "- **Maximum**: 24,576 tokens\n",
        "- **Recommended**: 512-2000 for simple tasks, 2000-5000 for complex reasoning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Testing with thinking_budget=0\n",
            "============================================================\n",
            "\n",
            "ğŸ”§ API PARAMETERS\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Max output tokens: 3000\n",
            "Thinking budget: 0\n",
            "\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“Š TOKEN USAGE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Prompt tokens:     757\n",
            "Completion tokens: 1\n",
            "Total tokens:      758\n",
            "\n",
            "ğŸ’° COST\n",
            "Input cost:        $0.000057\n",
            "Output cost:       $0.000000\n",
            "Call cost:         $0.000057\n",
            "\n",
            "âœ¨ RESPONSE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Content: 0\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ğŸ“ˆ CUMULATIVE STATISTICS\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Total prompt tokens:     757\n",
            "Total completion tokens: 1\n",
            "Total tokens:            758\n",
            "\n",
            "ğŸ’° Total estimated cost: $0.000057\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "\n",
            "============================================================\n",
            "Testing with thinking_budget=512\n",
            "============================================================\n",
            "\n",
            "ğŸ”§ API PARAMETERS\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Max output tokens: 3000\n",
            "Thinking budget: 512\n",
            "\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“Š TOKEN USAGE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Prompt tokens:     757\n",
            "Completion tokens: 1\n",
            "Thinking tokens:   29\n",
            "â”œâ”€ Thinking:       29\n",
            "â””â”€ Output:         1\n",
            "Total tokens:      787\n",
            "\n",
            "ğŸ’° COST\n",
            "Input cost:        $0.000057\n",
            "Output cost:       $0.000009\n",
            "Call cost:         $0.000066\n",
            "\n",
            "âœ¨ RESPONSE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Content: 1\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ğŸ“ˆ CUMULATIVE STATISTICS\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Total prompt tokens:     757\n",
            "Total completion tokens: 1\n",
            "Total thinking tokens:   29\n",
            "Total tokens:            787\n",
            "\n",
            "ğŸ’° Total estimated cost: $0.000066\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "\n",
            "============================================================\n",
            "Testing with thinking_budget=2000\n",
            "============================================================\n",
            "\n",
            "ğŸ”§ API PARAMETERS\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Max output tokens: 3000\n",
            "Thinking budget: 2000\n",
            "\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“Š TOKEN USAGE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Prompt tokens:     757\n",
            "Completion tokens: 1\n",
            "Thinking tokens:   1,998\n",
            "â”œâ”€ Thinking:       1,998\n",
            "â””â”€ Output:         1\n",
            "Total tokens:      2,756\n",
            "\n",
            "ğŸ’° COST\n",
            "Input cost:        $0.000057\n",
            "Output cost:       $0.000600\n",
            "Call cost:         $0.000656\n",
            "\n",
            "âœ¨ RESPONSE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Content: 1\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ğŸ“ˆ CUMULATIVE STATISTICS\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Total prompt tokens:     757\n",
            "Total completion tokens: 1\n",
            "Total thinking tokens:   1,998\n",
            "Total tokens:            2,756\n",
            "\n",
            "ğŸ’° Total estimated cost: $0.000656\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "\n",
            "============================================================\n",
            "Testing with thinking_budget=5000\n",
            "============================================================\n",
            "\n",
            "ğŸ”§ API PARAMETERS\n",
            "Model: gemini-2.5-flash-lite-preview-09-2025\n",
            "Max output tokens: 3000\n",
            "Thinking budget: 5000\n",
            "\n",
            "Warning: API returned empty content\n",
            "Response object: sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=11>\n",
            ") candidates=[Candidate(\n",
            "  content=Content(\n",
            "    role='model'\n",
            "  ),\n",
            "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
            "  index=0\n",
            ")] create_time=None model_version='gemini-2.5-flash-lite-preview-09-2025' prompt_feedback=None response_id='08DmaNCUHO-_qtsP5eiKmQQ' usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  prompt_token_count=757,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=757\n",
            "    ),\n",
            "  ],\n",
            "  thoughts_token_count=2999,\n",
            "  total_token_count=3756\n",
            ") automatic_function_calling_history=[] parsed=None\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ğŸ“ˆ CUMULATIVE STATISTICS\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Total prompt tokens:     0\n",
            "Total completion tokens: 0\n",
            "Total tokens:            0\n",
            "\n",
            "ğŸ’° Total estimated cost: $0.000000\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "\n",
            "============================================================\n",
            "SUMMARY\n",
            "============================================================\n",
            "Budget=    0: Thinking=   0, Total=  758, Cost=$0.000057, Pred=0\n",
            "Budget=  512: Thinking=  29, Total=  787, Cost=$0.000066, Pred=1\n",
            "Budget= 2000: Thinking=1998, Total= 2756, Cost=$0.000656, Pred=1\n",
            "Budget= 5000: Thinking=   0, Total=    0, Cost=$0.000000, Pred=0\n"
          ]
        }
      ],
      "source": [
        "# Test different thinking budgets on a single jet\n",
        "test_jet = X[0]\n",
        "\n",
        "budgets = [0, 512, 2000, 5000]\n",
        "results = []\n",
        "\n",
        "for budget in budgets:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Testing with thinking_budget={budget}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    clf_test = LLMClassifier(\n",
        "        model_name=\"gemini-2.5-flash-lite-preview-09-2025\",\n",
        "        template_name=\"simple_list\",\n",
        "        format_type=\"list\",\n",
        "        templates_dir=str(Path.cwd().parent / 'templates'),\n",
        "        thinking_budget=budget,\n",
        "        max_tokens=3000\n",
        "    )\n",
        "    clf_test.fit([], [])\n",
        "    \n",
        "    pred = clf_test.predict([test_jet], verbose=True)[0]\n",
        "    \n",
        "    results.append({\n",
        "        'budget': budget,\n",
        "        'prediction': pred,\n",
        "        'thinking_tokens': clf_test.total_thinking_tokens,\n",
        "        'total_tokens': clf_test.total_prompt_tokens + clf_test.total_completion_tokens + clf_test.total_thinking_tokens,\n",
        "        'cost': clf_test.total_cost\n",
        "    })\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "for r in results:\n",
        "    print(f\"Budget={r['budget']:5d}: Thinking={r['thinking_tokens']:4d}, Total={r['total_tokens']:5d}, Cost=${r['cost']:.6f}, Pred={r['prediction']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on 100 Jets\n",
        "\n",
        "Run the classifier on 100 jets and compute metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing on 10 jets...\n",
            "True distribution: 9 quark, 1 gluon\n"
          ]
        }
      ],
      "source": [
        "# Select 100 jets\n",
        "n_test = 10\n",
        "X_test = X[:n_test]\n",
        "y_test = y[:n_test]\n",
        "\n",
        "print(f\"Testing on {n_test} jets...\")\n",
        "print(f\"True distribution: {(y_test == 1).sum()} quark, {(y_test == 0).sum()} gluon\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:46<02:01, 24.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: API returned empty content and no reasoning\n",
            "Finish reason: length\n",
            "Message object: ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning_details=[{'type': 'reasoning.encrypted', 'data': 'gAAAAABo5l1yp5st0hC078keJS1uCWcXtFOW8dT8bLoyFSTxxSPuMzk2i0g0r5ZHdTvsP4qc_6yYmBaDThaEcX-_HCpvhvUxWmTM9FDyX2iSZwJuFd5WPgeZeSB9OdzO4NXzjcH0N6VUUU85d96FbqaS0Q8vUYV7kspY62N1j4vJnmeBrt81lHdfZLU6G8HkyRf-DRJjr3Zw5SSF44IVOI_smKbN0tUAI4vkailXTHVzu-9w9lU_rMqoD0cquhB6hywyDXL7nwDgm2Fe4v8fzD7Bc2YuV0P6pa1kNEzVho_KlzJbjPKg2_URQFhwagmqcIUQM7v_dP_RSCQhiGP_5kGCMWpC0jdblj-MbTFSES5Gy_ldsssIBgPHg7DLVKSzd6RftpL69CMHG8BSnbo_wDM-YyxEVX9C4KXIZTB-HH-akRfg83AC9Hqa-z0nOowJ0EYKzb1D8qUSvHw8masll_JvYcW2BfdZUsA2MBCL_7ue7ysuL9v3iZ3Mjrg8EbCWF72_4N4OqNwn1s8jCdageH9-R5L5ygTdrmbJ_okp6bTmGRpfzScRSWbgd0wvvfPFU8iBwFwtO_VFb2IFLXxDun0eueioJz9eG5POYTb69d6vcNvgHMwuJaA8eWB4aD0ALRcLquwr8hdYz0TDBYwY4slNKs7iM-Aegryni_UGbaX8BcRXF9CVjDdNoqCDvzu6MXlnGdoraS9kfXeREfQhWgk0HdTR-Qhqbuub_n7t9SyetsIhYYtvBKiOxexqsVy2E4GZYYjGTtS-_hbhoVpiDTeDlB7gGRdiAD-84Qznt4gdci_9aSxrrya2z4d7e4bU02CeIuyi35AgCHLAhMNft7C85AznmkFlHoqKyij0kJbNE-niThzzHRX5V-Kkh0qyCP89NzyhP-nOdbsroh1L64-ztp-jnoMLS1JqpKDVdwXw2rhkE5pc2PX-5uZXFS0eAhMBm4uG8eaWFZyk-2IgRiRTTB3K4DPWym031wJVc73vucv6VvwEbR3FCRwq9JR4MS24mDvzzy4nw863nreH8uqPaZb9KujaJPSaMZ6ug-CUGvd_XzNlGPrartEY1o8ai1u1VlW8LP4irBq5F-Y1wTXEnxi8itIMIeHKjXVL38WUY8dESwLHX4njY6kkIOx6WU18gdmEk5sjZO88N7iU6ZDp8obpSpfD2Sv0Lb97TzQp5MiOTZl2rINq0DRK7WvQfafp6aarwqXy8yUmxng5Uz0hDK61dTxceu--52JrZM9xp6VgU-I4LL5_Ody8_-PaMdmdelw1Is6O6lkB9-zRqj3q-CMLWOT6Bq_lOVpUq5iwQoDxEEPCqB89rVnQqQjhaMcdFpHhkdkjxNLOA8Ppv-HvkbsmEcrfUguGA8YiCicUxcmxvb7BI61SK67jL5eZQUilgPSjPAN_gzsu5usWhq8DB0rGjG9CZwk0s57yLJPg7B8-6ruOK4NMCEFn2PgCT0FvvFByR1b1MyGdQhdPvxVjwo2k2ES9iEwpQWkzVvxplTyIxRMoqUaHJARlPuxHnAEi0Ov47jHSTx2W7_ZiUZn7x-4g6Zc5wzQ8m_Z1kzLObh-Wx-efTvJc2I_Mnf8aB4Aeh6Arj4ZD6JAU7-4UYlUooYzvAegP0bp1P59q7wqwu3bQHZ13_WQs2IT_fnf0UR7HrsoTyXOkBPPwkGNgbbUg2Q2-Zg6CEGw5I_o-vuTfEY4zq98Le-Lsy8PZiKs7ULtnMOZp3WNqze38V2W9EZLbFGj2cF7czYpZg01m3C7ONEmWaN17J54Zr8ICOjPKpMKmmrccTc8mCDLO7N06tkoI9esYfcqQ2dOiKjkf8Pn-1W4NYkN_5e4s-3wMVhLWdaXX1JulDo96Lv4Azr4brbMGZdGGhdt6O3EHpzxSL_tNBeQuB93bMnzFCfPB5Lz5sKsoAR7FnTHDohJxqe_GH3lOqmsWaqvhFN9a0vHanI3KPIPwcuXG4VoVpIDG3akOOSLItaNbooQI7zHfMyRU0EY3PSVGHy4siLYhyZJjXnlLP_xOc3UKKcAk0i9r8FYiVPAM7jrCR6q5R6Z7KGqz5T3GIXqeb3YFttlrQ5BGwgPYsZyNsyUKvL7B7dalxKMF7bUu5NV1WaIDG52TGXQfbfwP_P6omu9Ow0PRQuhd5iH3xHBqJ_MlpAkeHQmJTwiA_8vYYu5pVF0eIojo3ucJnlimDD4GD0E8kK_mLShist2WMXV5vTpLhxU3_BrZj5MwFmFfeY9mPef_Ewj_HANofxXXBttn4IxNvhJpCVtoWkU4m7U31Ktlh_XEGqRR-EJaNMAnLvwHC9gmY5CmfsiiAcWxINIZm-iZZ0n-oBx79BoNuv_mrNNZKq8m4mnitoo86pK7zkW7bXS-tmFsPkO0H3DDDS_rgm2CRdRUTn44oVYocgQsWnOKF9GReTqUrB3kvCOI78dYw_euTzV7FVTyDUg99fX80Wl6r6ZbNEd26V8Y7HohaPsa-0WOb4i65x-KuzPd4oLRUFxE7s4vrgGTi0wkttF_wFb12t3ffjINxrn2vZA_hERMcqG6iNbYKL1WY8X40MfekOl6r2gDGoHVy6-3WzIuIY6K6Id3JgkZPs-JMiszpBBieJnIUsL8vjjy9iYTirpCJY5XPlH4ckYG7PLkh1QJP150K2jKu-9Mf-thd0GStTLYUsXLX3MFujifB5BlJ0ZK33kf3P8W1CMpF9EXB3II0opi5HVkOy0wNmePk7eC73kb9G-0iean-i3Rx2B-AbKVrXtqyWdDLkHKBGNiMCXgYqZxKGV_Bpm6QpOnfcgUg3MCIlLCM0cOYZm66rJP6cqRpIbdLD0sebtASNnUr0tJt0BNuFMtzAXbluDCuvwa9jMshgmwkg4dPnTAysJ3SGRj_StYhtT08eInVkXBjWyfCKgDGoZhRf19V7UxU5vcH3kZtO0QHfaoaPWky5Uj42ig7kwynfL4T2fZNsM9_D6l_lZD1XUEK0l9gua3nBfawj8fWJVTnol4ZlbN1nz7456F7Y09Mo5XFyeXPOJnatCm7lhJ4wbJ_UP0xLHjlSSLHH2KSqOoNc_-rkVFsKR6-Bs2ngARRC9h6RArqYHPk6DDaaiDN5uVhJZK9JR_ZbcYEdA0hnYPPKaEDZTQF5TgvayoVym4IPvxNtIhM-Sgd79-RL9HR2FQBYya-eCMMGaqNCOwCkp5-ubeqyvm40352s1nc-Nr4m_ysUKdM7VFJnuNhX2i9kNdH2uHY9CyLIL76SveDEjzlUWgRUPjunIZTbxjay0TN5oW5vp2akE-XWv80nZ0UraOZgDod0daY-BOZxDYFNrunc3iBUjSIikM7nGBrnLFUrUCYaGQRymRLBKZUQV4S4YXu2CEKw90mEaEAhEHC0p3_o1UDsVEV8Y76FGJgYtwQROB4lV_p-0uQf616nzl8zjTLsWOyY4pgnYX_Z8LTgBTASI6zGuZhTLlXb4H_HP0gG0pHUxcje-_shXY37wPa1ltMn3Uh_xPyS8YeT9XED1MpO1wVzbx80pnSc5n7hoaCNb8YsB75EDK-g7Rn_D59Mf1ScCDeHJreX1duvzGhDl8r_MNcvbUq1doSRvMLp-lKnIY4d5FsWtcgAoR6IY34vs-qPpDCwSSusE6eR_YKALgXw0SZfMeftLvpyhbt38SuGiOtAj99zzU7nLoJ0i8s37me3hGJTDUS_dbIvD4xwo1m7kXkTDMsugCojbOURdLR1YYcn9V8mbGirhvZWswixh-YUJb09Z-RME17MXuVGnA8hzWprqMUpmM6Hyl2LNnowrvUksVmGAz87Y28n6Q3af3uGHVzh8EEVGMvDo6oZtFguZRwDM_AyZAwf6D3y9jkHKvHQhaGfxxY2nwxbj1PGeoYrv3xy_RX2CvclquAcuM2_RFK-RL-mQqbsc3Z_yb2sEWHSqQZGnqi6M4x17TOPS_JkbDNVm3sGkbWPjCp4ELqmwVU1i-6JGL3-AsTP9HG9Id67SP8-NmlEvQ9f85dT7R86izXgTFh6mLO-JjHJfQeURLrMTFoj2cZemhwj3mKDwD8oSFi_qFWXKJpogwZQ95GgbnsA8etI1-LZhf5HsOO68LMMPXI6Vd1QBcKos6SqLDeB-9ASojxjSa0YumjZtuCNnAGk6LHl6VrEJDI-9jfNRQmE9qo8Ulu5ToZ2_ohvtQ2rzK2kkWb6cUvVl1ypnDX-o6arGpk6P_5_4qCRS5PCqGibzr_7Qm309OQjNBSiwsWWvUIJstP8SmcEChe2Lgb-dGeVM1IenfcU8Ex4RCgBDUW7ICkIBlcO3IBp31z2oI78zcQbY1NzQbYwNG4JlChAXarm0b69-7KnjG-BkK2RUq_LCDT5ym81gz6ZNepeIinLipkf2Dp12Fvxdc33396SQaPIE2BTduQCXAK9Iuie9Qhfx-OT16m2qlcoYpBTM2BNOM3dEVz1OCZQur_yXRkLE7lxGo3pip-1WRN06XhiMqnZHetDzUCVIbiJVGgQlF_HGe0wsuohUoLaEXrMHU9JdgWyYS6E0qII66h8b3kGuwB3yGeQOlyi_yX-WTqTaKtP0PfYxOXctbhtd4UfaqzpyPOh6xfnC4BtfYFjHWejS4wD_SVoKOfSL_PsPrMkZdgO2bsCh0zONXl5sYMYFbTpFaTaMjON1MR56kP9XN0Qrhdi1j8VVSXuvrU2Wdf2jesxY_BGiGpoQFP3PxD7GyTlnAWwF4ZIEniD4-TvY_oQAmjWyY3-Y1_jMqkD71iTNZClPFXj7D4mXxr_9xEo7-ii1FdZthQgUH1GDnJ-EbLq-HdIW6zSpjEuBfNlhmOqmXi2uf_Az1HYB4b4kxZbOubh0nH8YRROVoJKQPlUsmiZrsrG2F9_iSv9IA9nDdUCpcs-x-H18eto_E2bd5mP_CoVhIA5-ieGoC_jtsbnEzYmcgjHi5UrlZywnFaYMXBgFVDdX8zTl19NOzsXYyJS5nyFiWXrcXcdc13NIBqTl9XA5i7gc53iQ-CFilE_JvF6IxhLJYNTmeNyqufWWIXRgZBl0_KiuUgpJhB4PwcGRlqz8pMeNgzq-TZ4yfalV55LmNQqFOFQdtjXcgNa7uTUE6c5HOKjHLiQaAdscMUG6BUxGoIjzfJhWNmRNGT495ncq1H-A3EGl5CLlqwgIShSiTCtoglSZfvipriklycEA8o4ztN13kVwLPeTzWeV9XRPxECvLHsoehmiwWm4k7TS38ac7uh3m5GU7Icv10IvU6XAVdscst8dBQpnOuZL-hlLsd8mHQA7BYQNigioLDS9MjlYAh4dty7wzZgPfN9vvrdXmsKRcIiIZE8Zy30pPjTtgHcSD048eBTR_E35XEC2g2NkF3GuJ1ieP3qNepipNtrymetaGrzVcEuwjjeAigUKLijBPd9l3G2l38f5fyXmNCHzNppFn2oV26repsTQat4t4PwOBzX4CzLVZ2shgyJpE3Wk0z6w0CeNvr9PhV42A7UouYfLcfhoZ979I0NMjGSNRYLO1G0_T7l0X8vWffYkFo0XQWsynz7o4HKOP6Qd4tCz4FRFBgtV7DhUmEyA3bTtcD2V5o0w55C_muVxG3lEdT5GhUNBzqLN2ulmGfJ_lCp2-ItCEy7W0fSTWLhEfAsicceZOxizfQvA7yJGUNEebvd8YGhXRlxjAPLAhA1tjOhN3Y-R0pCY8BE2S9sCstutXb-50ho_9Um5Lmiz1ZDJS4yGBx-Qvy-HlVtupv7D6Xltk4Lk936xOwD43-ZDbG8dD3dZTxIyBNx_9jXjal', 'id': 'rs_0bbb9ba754eaed2e0168e65d6276bc8190b1a11fca3804adaf', 'format': 'openai-responses-v1', 'index': 0}])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:59<00:00, 17.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After 10 jets: Accuracy = 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions (this will take a while)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "predictions = []\n",
        "for i, jet in enumerate(tqdm(X_test)):\n",
        "    pred = clf.predict([jet])[0]\n",
        "    predictions.append(pred)\n",
        "    \n",
        "    # Print progress every 10 jets\n",
        "    if (i + 1) % 10 == 0:\n",
        "        acc = accuracy_score(y_test[:i+1], predictions)\n",
        "        print(f\"After {i+1} jets: Accuracy = {acc:.3f}\")\n",
        "\n",
        "predictions = np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "RESULTS\n",
            "==================================================\n",
            "Accuracy: 0.800\n",
            "AUC Score: 0.889\n",
            "\n",
            "Predicted distribution: 7 quark, 3 gluon\n",
            "True distribution: 9 quark, 1 gluon\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "auc = roc_auc_score(y_test, predictions)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESULTS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"AUC Score: {auc:.3f}\")\n",
        "print(f\"\\nPredicted distribution: {(predictions == 1).sum()} quark, {(predictions == 0).sum()} gluon\")\n",
        "print(f\"True distribution: {(y_test == 1).sum()} quark, {(y_test == 0).sum()} gluon\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "                Predicted\n",
            "                Gluon  Quark\n",
            "True  Gluon         1      0\n",
            "      Quark         2      7\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"                Predicted\")\n",
        "print(\"                Gluon  Quark\")\n",
        "print(f\"True  Gluon     {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
        "print(f\"      Quark     {cm[1,0]:5d}  {cm[1,1]:5d}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
