{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88ff677",
   "metadata": {},
   "source": [
    "# Local LLM Classifier Test\n",
    "\n",
    "Test the LocalLLMClassifier on quark/gluon jet data using local OpenAI-compatible API.\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Zero-shot jet classification with GPT-OSS-120B (or any reasoning model)\n",
    "- Reasoning effort control (low, medium, high)\n",
    "- Async vs sequential processing comparison\n",
    "- Token usage tracking (local server, no cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42728186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from vibe_jet_tagging.local_llm_classifier import LocalLLMClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b378cc",
   "metadata": {},
   "source": [
    "## Check Local Server\n",
    "\n",
    "Make sure your local LLM server is running.\n",
    "\n",
    "Example with vLLM:\n",
    "```bash\n",
    "vllm serve openai/gpt-oss-120b --port 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af8ef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Local LLM server is running\n",
      "Available models: ['openai/gpt-oss-120b']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Check if server is running\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8000/v1/models\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        print(\"âœ… Local LLM server is running\")\n",
    "        print(f\"Available models: {[m['id'] for m in models['data']]}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Server responded but with error\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ Local LLM server not reachable\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nStart the server with: vllm serve openai/gpt-oss-120b --port 8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbfd862",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the quark/gluon jet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030da700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 jets\n",
      "X shape: (100000, 139, 4)\n",
      "y shape: (100000,)\n",
      "Quark jets: 50000\n",
      "Gluon jets: 50000\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_path = Path.cwd().parent / 'data' / 'qg_jets.npz'\n",
    "data = np.load(data_path)\n",
    "\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "print(f\"Loaded {len(X)} jets\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Quark jets: {(y == 1).sum()}\")\n",
    "print(f\"Gluon jets: {(y == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6809122",
   "metadata": {},
   "source": [
    "## Initialize LocalLLMClassifier\n",
    "\n",
    "Set up the classifier with local OpenAI-compatible API.\n",
    "\n",
    "**Configuration:**\n",
    "- `model_name`: The model identifier (must match server)\n",
    "- `reasoning_effort`: Controls reasoning depth (\"low\", \"medium\", \"high\")\n",
    "- `base_url`: URL of your local server\n",
    "- `api_key`: \"EMPTY\" for local servers without auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e99a3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier initialized\n",
      "Model: openai/gpt-oss-120b\n",
      "Template: simple_list\n",
      "Format: list\n",
      "Reasoning effort: medium\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier with local API\n",
    "clf = LocalLLMClassifier(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    template_name=\"simple_list\",\n",
    "    format_type=\"list\",\n",
    "    templates_dir=str(Path.cwd().parent / 'templates'),\n",
    "    reasoning_effort=\"medium\",   # Options: \"low\", \"medium\", \"high\"\n",
    "    reasoning_summary=\"auto\",    # Options: \"auto\", \"concise\", \"detailed\"\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\"\n",
    ")\n",
    "\n",
    "# Fit (no-op for zero-shot)\n",
    "clf.fit([], [])\n",
    "\n",
    "print(\"Classifier initialized\")\n",
    "print(f\"Model: {clf.model_name}\")\n",
    "print(f\"Template: {clf.template_name}\")\n",
    "print(f\"Format: {clf.format_type}\")\n",
    "print(f\"Reasoning effort: {clf.reasoning_effort}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e563b1",
   "metadata": {},
   "source": [
    "## Test Single Jet Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a78d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1.0 (quark)\n",
      "\n",
      "Jet shape: (139, 4)\n",
      "Number of particles (pt > 0): 18\n",
      "\n",
      "ğŸ”§ API PARAMETERS\n",
      "Model: openai/gpt-oss-120b\n",
      "Reasoning effort: medium\n",
      "Reasoning summary: auto\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TOKEN USAGE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Prompt tokens:     0\n",
      "Completion tokens: 0\n",
      "Total tokens:      892\n",
      "\n",
      "ğŸ’° COST\n",
      "Input cost:        $0.000000\n",
      "Output cost:       $0.000000\n",
      "Call cost:         $0.000000\n",
      "\n",
      "âœ¨ RESPONSE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Content: We need classify quark vs gluon jet based on given particle list. The jet appears to be dominated by photons (pid=22) and some charged pions, kaons. High multiplicity? Actually many photons, especially very high pt photon (335 GeV) - that's huge energy likely from jet core? The presence of many photons could indicate electromagnetic component maybe from quark jets (e.g., neutral pion decays produce photons). Gluon jets tend to have higher multiplicity and softer spectrum. Here we have a relatively small number of particles (18) but the highest pt is 335 GeV photon, then 44 GeV photon, 37 GeV photon, etc. The distribution seems heavily weighted to a few high-pt particles, which is characteristic of quark jets (harder fragmentation). Gluon jets have more particles and softer distribution. So likely quark jet.\n",
      "\n",
      "Thus answer 1. 1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“ˆ CUMULATIVE STATISTICS\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Total prompt tokens:     0\n",
      "Total completion tokens: 0\n",
      "Total tokens:            0\n",
      "\n",
      "ğŸ’° Total estimated cost: $0.000000\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "Predicted label: 1 (quark)\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "# Test on a single jet\n",
    "test_jet = X[0]\n",
    "true_label = y[0]\n",
    "\n",
    "print(f\"True label: {true_label} ({'quark' if true_label == 1 else 'gluon'})\")\n",
    "print(f\"\\nJet shape: {test_jet.shape}\")\n",
    "print(f\"Number of particles (pt > 0): {(test_jet[:, 0] > 0).sum()}\")\n",
    "\n",
    "# Make prediction (sequential mode for single jet)\n",
    "prediction = clf.predict([test_jet], verbose=True, use_async=False)[0]\n",
    "print(f\"\\nPredicted label: {prediction} ({'quark' if prediction == 1 else 'gluon'})\")\n",
    "print(f\"Correct: {prediction == true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebec17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PROMPT PREVIEW\n",
      "================================================================================\n",
      "Model: openai/gpt-oss-120b\n",
      "Template: simple_list\n",
      "Format: list\n",
      "Reasoning effort: medium\n",
      "Reasoning summary: auto\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "You are a particle physics expert. Your task is to classify whether a jet is initiated by a quark (label: 1) or a gluon (label: 0).\n",
      "\n",
      "A jet consists of particles, each with the following properties:\n",
      "- pt: transverse momentum (GeV)\n",
      "- y: rapidity\n",
      "- phi: azimuthal angle (radians)\n",
      "- pid: particle ID\n",
      "\n",
      "Here is the jet data:\n",
      "Particle 1: pt=0.269 GeV, y=0.357, phi=4.741, pid=22\n",
      "Particle 2: pt=0.160 GeV, y=-0.256, phi=4.550, pid=22\n",
      "Particle 3: pt=1.149 GeV, y=-0.062, phi=4.504, pid=-211\n",
      "Particle 4: pt=4.132 GeV, y=0.174, phi=4.766, pid=-321\n",
      "Particle 5: pt=1.696 GeV, y=-0.212, phi=4.797, pid=-211\n",
      "Particle 6: pt=2.194 GeV, y=-0.052, phi=4.576, pid=22\n",
      "Particle 7: pt=1.619 GeV, y=-0.068, phi=4.646, pid=22\n",
      "Particle 8: pt=6.592 GeV, y=0.044, phi=4.766, pid=211\n",
      "Particle 9: pt=3.771 GeV, y=0.042, phi=4.755, pid=321\n",
      "Particle 10: pt=13.482 GeV, y=-0.028, phi=4.735, pid=-211\n",
      "Particle 11: pt=4.108 GeV, y=-0.024, phi=4.759, pid=22\n",
      "Particle 12: pt=21.646 GeV, y=-0.027, phi=4.760, pid=22\n",
      "Particle 13: pt=6.776 GeV, y=-0.030, phi=4.761, pid=22\n",
      "Particle 14: pt=13.255 GeV, y=-0.039, phi=4.749, pid=22\n",
      "Particle 15: pt=2.984 GeV, y=-0.037, phi=4.746, pid=22\n",
      "Particle 16: pt=37.374 GeV, y=-0.035, phi=4.755, pid=22\n",
      "Particle 17: pt=335.399 GeV, y=-0.033, phi=4.751, pid=22\n",
      "Particle 18: pt=44.214 GeV, y=-0.033, phi=4.754, pid=22\n",
      "\n",
      "Based on the particle content and kinematics, is this a quark jet (1) or gluon jet (0)?\n",
      "\n",
      "Respond with ONLY the number 0 or 1, nothing else.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Preview the prompt\n",
    "clf.preview_prompt(test_jet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc085d",
   "metadata": {},
   "source": [
    "## Reasoning Effort Control\n",
    "\n",
    "Test how different reasoning effort levels affect performance and token usage.\n",
    "\n",
    "For reasoning models:\n",
    "- **low**: Fast reasoning with minimal depth (~1,250 tokens)\n",
    "- **medium**: Balanced reasoning (~1,760 tokens)\n",
    "- **high**: Deep reasoning with maximum effort (~7,540 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c074575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing with reasoning_effort=low\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ API PARAMETERS\n",
      "Model: openai/gpt-oss-120b\n",
      "Reasoning effort: low\n",
      "Reasoning summary: auto\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TOKEN USAGE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Prompt tokens:     0\n",
      "Completion tokens: 0\n",
      "Total tokens:      764\n",
      "\n",
      "ğŸ’° COST\n",
      "Input cost:        $0.000000\n",
      "Output cost:       $0.000000\n",
      "Call cost:         $0.000000\n",
      "\n",
      "âœ¨ RESPONSE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Content: We need guess: many photons (pid 22) and few hadrons. Gluon jets tend to have higher multiplicity, softer spectrum. Here high pT photons dominate, suggests maybe quark radiating photons? Hard to say. Probably quark jet. I'd answer 1. 1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“ˆ CUMULATIVE STATISTICS\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Total prompt tokens:     0\n",
      "Total completion tokens: 0\n",
      "Total tokens:            0\n",
      "\n",
      "ğŸ’° Total estimated cost: $0.000000\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing with reasoning_effort=medium\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ API PARAMETERS\n",
      "Model: openai/gpt-oss-120b\n",
      "Reasoning effort: medium\n",
      "Reasoning summary: auto\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TOKEN USAGE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Prompt tokens:     0\n",
      "Completion tokens: 0\n",
      "Total tokens:      1,194\n",
      "\n",
      "ğŸ’° COST\n",
      "Input cost:        $0.000000\n",
      "Output cost:       $0.000000\n",
      "Call cost:         $0.000000\n",
      "\n",
      "âœ¨ RESPONSE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Content: We need to determine a classification. The jet is composed largely of photons (pid=22) and some charged pions (211, -211) and kaons (321, -321). The leading particle is a photon with pt 335 GeV, also many high-pt photons. A quark jet typically has more leading hadron, often a leading charged hadron, while gluon jets have higher particle multiplicity and softer distribution, more spread, and larger radiation, but also more particles. This jet has many particles? Count: 18 particles, with one extremely high pt (335 GeV) photon, plus others. Many photons perhaps from EM shower? Might be a photon-initiated jet (like an \"electromagnetic\" jet) which could be more quark-like? But classification seems based on typical differences: gluon jets have larger multiplicity and broader, softer fragmentation function. Quark jets have harder fragmentation (leading particle carries large fraction of jet energy). Here leading particle carries huge fraction (335 out of sum). Sum pt: let's approximate: major contributions: 335 + 44 + 37 + 21.6 + 13.5 + 13.3 + 6.8 + 6.6 + 4.13 + 4.11 + 3.77 + 2.98 + 2.19 + 1.62 + 1.70 + 1.15 + 0.27 + 0.16 = approximate: 335+44=379, +37=416, +21.6=437.6, +13.5=451.1, +13.3=464.4, +6.8=471.2, +6.8=~478, +4.13=482.1, +4.11=486.2, +3.77=490, +2.98=493, +2.19=495, +1.62=496.6, +1.70=498.3, +1.15=499.5, +0.27=499.8, +0.16=499.96 GeV. So leading particle holds 335/500 ~ 67% fraction, very high. That's typical of a quark jet (hard fragmentation). So answer likely 1.\n",
      "\n",
      "Thus output \"1\". 1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“ˆ CUMULATIVE STATISTICS\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Total prompt tokens:     0\n",
      "Total completion tokens: 0\n",
      "Total tokens:            0\n",
      "\n",
      "ğŸ’° Total estimated cost: $0.000000\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing with reasoning_effort=high\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ API PARAMETERS\n",
      "Model: openai/gpt-oss-120b\n",
      "Reasoning effort: high\n",
      "Reasoning summary: auto\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TOKEN USAGE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Prompt tokens:     0\n",
      "Completion tokens: 0\n",
      "Total tokens:      1,476\n",
      "\n",
      "ğŸ’° COST\n",
      "Input cost:        $0.000000\n",
      "Output cost:       $0.000000\n",
      "Call cost:         $0.000000\n",
      "\n",
      "âœ¨ RESPONSE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Content: We need to classify jet as quark-initiated vs gluon-initiated, using the given particles' properties: pt, rapidity y, phi, pid (PDG particle ID). Jet consists of many particles: a large number of photons (pid=22), some pions (+/- 211), kaons (+/-321), and maybe a few others.\n",
      "\n",
      "We need to decide based on typical characteristics: quark jets generally have lower multiplicity and harder fragmentation (higher leading particle fraction). Gluon jets have higher particle multiplicity and softer fragmentation, more spread (more many low-pT particles, more gluon radiation). In experiments, the average fraction of jet pt carried by leading particle is higher for quark jets; gluon jets have more equal sharing.\n",
      "\n",
      "Given this jet appears to have many particles with very high pt: a leading photon/neutral particle with pt=335 GeV (pid=22). That's huge fraction of the jet: the sum of pt of all particles ~? Let's sum: We'll compute approximate sum.\n",
      "\n",
      "List:\n",
      "1: 0.269\n",
      "2: 0.160\n",
      "3: 1.149\n",
      "4: 4.132\n",
      "5: 1.696\n",
      "6: 2.194\n",
      "7: 1.619\n",
      "8: 6.592\n",
      "9: 3.771\n",
      "10: 13.482\n",
      "11: 4.108\n",
      "12: 21.646\n",
      "13: 6.776\n",
      "14: 13.255\n",
      "15: 2.984\n",
      "16: 37.374\n",
      "17: 335.399\n",
      "18: 44.214\n",
      "\n",
      "Sum = let's sum step:\n",
      "\n",
      "0.269+0.160=0.429\n",
      "+1.149=1.578\n",
      "+4.132=5.710\n",
      "+1.696=7.406\n",
      "+2.194=9.600\n",
      "+1.619=11.219\n",
      "+6.592=17.811\n",
      "+3.771=21.582\n",
      "+13.482=35.064\n",
      "+4.108=39.172\n",
      "+21.646=60.818\n",
      "+6.776=67.594\n",
      "+13.255=80.849\n",
      "+2.984=83.833\n",
      "+37.374=121.207\n",
      "+335.399=456.606\n",
      "+44.214=500.820\n",
      "\n",
      "Thus total pt approx 500.8 GeV. Leading particle (pt=335.399) carries about 66.9% of total jet pt. That's high. This suggests a quark-initiated jet (hard fragmentation). Additionally the leading particle is a photon. If a QCD jet, photon may come from neutral pion decay or prompt photon, but high-pt photon could indicate a quark radiating a photon, albeit unusual. But in classification based on typical QCD jets, the large leading fraction suggests quark.\n",
      "\n",
      "Also multiplicity: only 18 particles, moderate. Not huge multiplicity typical of gluon jets (usually bigger). Indeed, gloun jets have roughly ~1.5 times higher multiplicity. Here number of particles moderate.\n",
      "\n",
      "Also composition includes many photons and neutral pions leads to high electromagnetic fraction; quark jets higher EM fraction? Actually sometimes gluon jets have more particles leading to more fragmentation into pi0s, also EM fraction may be high. But the dominant factor is leading pT.\n",
      "\n",
      "Check if any presence of heavy flavor? No charged leptons. There's kaons (pid +-321) present: one K- and one K+. Also multiple pions. So typical QCD.\n",
      "\n",
      "Thus classification: quark-initiated: label 1.\n",
      "\n",
      "Therefore answer: \"1\". 1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“ˆ CUMULATIVE STATISTICS\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Total prompt tokens:     0\n",
      "Total completion tokens: 0\n",
      "Total tokens:            0\n",
      "\n",
      "ğŸ’° Total estimated cost: $0.000000\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Effort     Reasoning    Total        Time       Pred\n",
      "----------------------------------------------------------------------\n",
      "low        0            0            0.60      s 1\n",
      "medium     0            0            2.89      s 1\n",
      "high       0            0            4.54      s 1\n"
     ]
    }
   ],
   "source": [
    "# Test different reasoning efforts on a single jet\n",
    "test_jet = X[0]\n",
    "\n",
    "efforts = [\"low\", \"medium\", \"high\"]\n",
    "results = []\n",
    "\n",
    "for effort in efforts:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing with reasoning_effort={effort}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    clf_test = LocalLLMClassifier(\n",
    "        model_name=\"openai/gpt-oss-120b\",\n",
    "        template_name=\"simple_list\",\n",
    "        format_type=\"list\",\n",
    "        templates_dir=str(Path.cwd().parent / 'templates'),\n",
    "        reasoning_effort=effort,\n",
    "        base_url=\"http://localhost:8000/v1\",\n",
    "        api_key=\"EMPTY\"\n",
    "    )\n",
    "    clf_test.fit([], [])\n",
    "    \n",
    "    start = time.time()\n",
    "    pred = clf_test.predict([test_jet], verbose=True, use_async=False)[0]\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    results.append({\n",
    "        'effort': effort,\n",
    "        'prediction': pred,\n",
    "        'reasoning_tokens': clf_test.total_reasoning_tokens,\n",
    "        'total_tokens': clf_test.total_prompt_tokens + clf_test.total_completion_tokens + clf_test.total_reasoning_tokens,\n",
    "        'time': elapsed\n",
    "    })\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Effort':<10} {'Reasoning':<12} {'Total':<12} {'Time':<10} {'Pred'}\")\n",
    "print(\"-\" * 70)\n",
    "for r in results:\n",
    "    print(f\"{r['effort']:<10} {r['reasoning_tokens']:<12,} {r['total_tokens']:<12,} {r['time']:<10.2f}s {r['prediction']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f420e",
   "metadata": {},
   "source": [
    "## Async vs Sequential Comparison\n",
    "\n",
    "Compare async (concurrent) vs sequential processing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3435e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 20 jets...\n",
      "True distribution: 14 quark, 6 gluon\n"
     ]
    }
   ],
   "source": [
    "# Select test jets\n",
    "n_test = 20\n",
    "X_test = X[:n_test]\n",
    "y_test = y[:n_test]\n",
    "\n",
    "print(f\"Testing on {n_test} jets...\")\n",
    "print(f\"True distribution: {(y_test == 1).sum()} quark, {(y_test == 0).sum()} gluon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceccfa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ASYNC MODE (Concurrent Processing)\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m clf_async.fit([], [])\n\u001b[32m     17\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m predictions_async = \u001b[43mclf_async\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_async\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m time_async = time.time() - start\n\u001b[32m     21\u001b[39m accuracy_async = accuracy_score(y_test, predictions_async)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vibe-jet-tagging/src/vibe_jet_tagging/local_llm_classifier.py:152\u001b[39m, in \u001b[36mLocalLLMClassifier.predict\u001b[39m\u001b[34m(self, X, verbose, use_async)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mClassifier must be fitted before predict\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_async:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# Use async for concurrent requests\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     predictions = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# Sequential processing\u001b[39;00m\n\u001b[32m    155\u001b[39m     predictions = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/asyncio/runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# Test ASYNC mode (default, much faster)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ASYNC MODE (Concurrent Processing)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "clf_async = LocalLLMClassifier(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    template_name=\"simple_list\",\n",
    "    format_type=\"list\",\n",
    "    templates_dir=str(Path.cwd().parent / 'templates'),\n",
    "    reasoning_effort=\"medium\",\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\"\n",
    ")\n",
    "clf_async.fit([], [])\n",
    "\n",
    "start = time.time()\n",
    "predictions_async = clf_async.predict(X_test, verbose=False, use_async=True)\n",
    "time_async = time.time() - start\n",
    "\n",
    "accuracy_async = accuracy_score(y_test, predictions_async)\n",
    "print(f\"\\nTime: {time_async:.2f}s ({time_async/n_test:.2f}s per jet)\")\n",
    "print(f\"Accuracy: {accuracy_async:.3f}\")\n",
    "print(f\"Total tokens: {clf_async.total_prompt_tokens + clf_async.total_completion_tokens + clf_async.total_reasoning_tokens:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4010cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SEQUENTIAL mode (slower, for comparison)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SEQUENTIAL MODE (One at a time)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "clf_seq = LocalLLMClassifier(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    template_name=\"simple_list\",\n",
    "    format_type=\"list\",\n",
    "    templates_dir=str(Path.cwd().parent / 'templates'),\n",
    "    reasoning_effort=\"medium\",\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\"\n",
    ")\n",
    "clf_seq.fit([], [])\n",
    "\n",
    "start = time.time()\n",
    "predictions_seq = clf_seq.predict(X_test, verbose=False, use_async=False)\n",
    "time_seq = time.time() - start\n",
    "\n",
    "accuracy_seq = accuracy_score(y_test, predictions_seq)\n",
    "print(f\"\\nTime: {time_seq:.2f}s ({time_seq/n_test:.2f}s per jet)\")\n",
    "print(f\"Accuracy: {accuracy_seq:.3f}\")\n",
    "print(f\"Total tokens: {clf_seq.total_prompt_tokens + clf_seq.total_completion_tokens + clf_seq.total_reasoning_tokens:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAsync mode:      {time_async:.2f}s ({time_async/n_test:.2f}s per jet)\")\n",
    "print(f\"Sequential mode: {time_seq:.2f}s ({time_seq/n_test:.2f}s per jet)\")\n",
    "print(f\"\\nSpeedup: {time_seq/time_async:.1f}x faster with async\")\n",
    "print(f\"\\nAccuracy (async):     {accuracy_async:.3f}\")\n",
    "print(f\"Accuracy (sequential): {accuracy_seq:.3f}\")\n",
    "print(f\"\\nPredictions match: {np.array_equal(predictions_async, predictions_seq)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234121fa",
   "metadata": {},
   "source": [
    "## Evaluate Performance on 100 Jets\n",
    "\n",
    "Run the classifier on more jets and compute detailed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192eb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 100 jets for evaluation\n",
    "n_eval = 100\n",
    "X_eval = X[:n_eval]\n",
    "y_eval = y[:n_eval]\n",
    "\n",
    "print(f\"Evaluating on {n_eval} jets...\")\n",
    "print(f\"True distribution: {(y_eval == 1).sum()} quark, {(y_eval == 0).sum()} gluon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using async (fastest)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "clf_eval = LocalLLMClassifier(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    template_name=\"simple_list\",\n",
    "    format_type=\"list\",\n",
    "    templates_dir=str(Path.cwd().parent / 'templates'),\n",
    "    reasoning_effort=\"medium\",\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\"\n",
    ")\n",
    "clf_eval.fit([], [])\n",
    "\n",
    "print(\"Making predictions (async mode)...\")\n",
    "start = time.time()\n",
    "predictions = clf_eval.predict(X_eval, verbose=False, use_async=True)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "print(f\"\\nCompleted in {elapsed:.2f}s ({elapsed/n_eval:.2f}s per jet)\")\n",
    "print(f\"Total tokens used: {clf_eval.total_prompt_tokens + clf_eval.total_completion_tokens + clf_eval.total_reasoning_tokens:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21ecb0",
   "metadata": {},
   "source": [
    "## Results and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ca49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_eval, predictions)\n",
    "auc = roc_auc_score(y_eval, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"AUC Score: {auc:.3f}\")\n",
    "print(f\"\\nPredicted distribution: {(predictions == 1).sum()} quark, {(predictions == 0).sum()} gluon\")\n",
    "print(f\"True distribution: {(y_eval == 1).sum()} quark, {(y_eval == 0).sum()} gluon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4dfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_eval, predictions)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                Predicted\")\n",
    "print(\"                Gluon  Quark\")\n",
    "print(f\"True  Gluon     {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
    "print(f\"      Quark     {cm[1,0]:5d}  {cm[1,1]:5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4297d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Gluon (0)', 'Quark (1)'],\n",
    "            yticklabels=['Gluon (0)', 'Quark (1)'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title(f'Confusion Matrix - Local LLM Classifier\\nAccuracy: {accuracy:.3f}, AUC: {auc:.3f}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef0911",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "Key takeaways from the local LLM classifier:\n",
    "\n",
    "1. **Async Processing**: Significantly faster than sequential (typically 5-10x speedup)\n",
    "2. **Reasoning Effort**: Higher effort levels use more tokens but may improve accuracy\n",
    "3. **Local Deployment**: No API costs, full control over infrastructure\n",
    "4. **Zero-Shot**: No training required, just prompt engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
